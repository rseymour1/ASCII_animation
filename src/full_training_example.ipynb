{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim\n",
    "%pip install torch\n",
    "%pip install Pillow\n",
    "%pip install requests\n",
    "%pip install open_clip_torch\n",
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for image: mps\n",
      "Using device for text: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gensim.downloader as api # pip install gensim\n",
    "import open_clip\n",
    "import os\n",
    "from txt2png import txt_to_png\n",
    "if torch.backends.mps.is_available():\n",
    "    from open_clip_test_mps import clip_loss, device, preprocess\n",
    "elif torch.cuda.is_available():\n",
    "    from open_clip_test_cuda import clip_loss, device, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 25\n",
    "x_dim = 25\n",
    "y_dim = 8\n",
    "output_size = y_dim * x_dim\n",
    "ascii_chars = \" .,:;+*#@$%&0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ-_=|/\\\\()[]{}\"\n",
    "num_chars = len(ascii_chars)\n",
    "char_to_index = {char: i for i, char in enumerate(ascii_chars)}\n",
    "index_to_char = {i: char for i, char in enumerate(ascii_chars)}\n",
    "\n",
    "class ASCIIArtGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_chars):\n",
    "        super(ASCIIArtGenerator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size * num_chars)\n",
    "        self.num_chars = num_chars\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(-1, self.output_size, self.num_chars)\n",
    "\n",
    "def generate_ascii_art(model, embedding, temperature=1.0):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    with torch.no_grad():\n",
    "        # Move the embedding to the model's device\n",
    "        embedding = embedding.to(device)\n",
    "        output = model(embedding.unsqueeze(0))\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        scaled_logits = output / temperature\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(scaled_logits, dim=2)\n",
    "        \n",
    "        # Sample from the distribution\n",
    "        indices = torch.multinomial(probs.view(-1, num_chars), 1).squeeze(-1)\n",
    "        \n",
    "        ascii_grid = \"\"\n",
    "        for i in range(y_dim):\n",
    "            for j in range(x_dim):\n",
    "                ascii_grid += index_to_char[indices[i * x_dim + j].item()]\n",
    "            ascii_grid += \"\\n\"\n",
    "        return ascii_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to handle the dataset\n",
    "class ASCIIArtDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_pairs, word_model):\n",
    "        \"\"\"\n",
    "        data_pairs: List of tuples (word, label_text, ascii_art)\n",
    "                    label_text: the label text like \"cat\", \"dog\"\n",
    "                    ascii_art: the target ASCII art as a string\n",
    "        word_model: Word embedding model\n",
    "        \"\"\"\n",
    "        self.data_pairs = data_pairs\n",
    "        self.word_model = word_model\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label_text, ascii_art = self.data_pairs[idx]\n",
    "        \n",
    "        # Get word embedding\n",
    "        word_embedding = torch.tensor(self.word_model[label_text], dtype=torch.float32)\n",
    "        \n",
    "        # Convert ASCII art to target indices\n",
    "        target_indices = []\n",
    "        for char in ascii_art:\n",
    "            if char == '\\n':\n",
    "                continue\n",
    "            target_indices.append(char_to_index.get(char, 0))  # Default to 0 if char not found\n",
    "            \n",
    "        # Pad or truncate to output_size\n",
    "        if len(target_indices) < output_size:\n",
    "            target_indices += [0] * (output_size - len(target_indices))\n",
    "        else:\n",
    "            target_indices = target_indices[:output_size]\n",
    "            \n",
    "        target_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
    "        \n",
    "        return word_embedding, target_tensor, label_text\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataset, candidate_labels, num_epochs, batch_size=1, learning_rate=0.001):\n",
    "    model.to(device)\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Define loss function for character prediction\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # CLIP model for semantic alignment\n",
    "    clip_model, preprocess = open_clip.create_model_from_pretrained('hf-hub:laion/CLIP-ViT-g-14-laion2B-s12B-b42K')\n",
    "    tokenizer = open_clip.get_tokenizer('hf-hub:laion/CLIP-ViT-g-14-laion2B-s12B-b42K')\n",
    "    clip_model.eval()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for word_emb, target_indices, label_text in dataloader:\n",
    "            word_emb = word_emb.to(device)\n",
    "            target_indices = target_indices.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(word_emb)\n",
    "            \n",
    "            # Reshape outputs for loss calculation\n",
    "            outputs_flat = outputs.view(-1, num_chars)\n",
    "            targets_flat = target_indices.view(-1)\n",
    "            \n",
    "            # Calculate character prediction loss\n",
    "            char_loss = criterion(outputs_flat, targets_flat)\n",
    "            \n",
    "            # Generate ASCII art and convert to image\n",
    "            ascii_art = generate_ascii_art(model, word_emb[0].cpu())\n",
    "            ascii_png = txt_to_png(ascii_art)\n",
    "            \n",
    "            # Calculate semantic alignment loss using CLIP\n",
    "            image_tensor = preprocess(ascii_png).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get the label for CLIP loss\n",
    "            #candidate_labels = [\"a bird\", \"a dog\", \"a cat\", \"a castle\"] # Customize based on your classes\n",
    "            true_label_index = candidate_labels.index(label_text[0])\n",
    "            \n",
    "            # Calculate CLIP loss\n",
    "            clip_loss_val = clip_loss(image_tensor, candidate_labels, true_label_index)\n",
    "            \n",
    "            # Combine losses - you can adjust the weights\n",
    "            loss = char_loss * 0.5 + clip_loss_val * 0.5\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Print epoch stats\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Print example generation\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(\"Example generation:\")\n",
    "            print(ascii_art)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example of how to create and use the dataset\n",
    "def prepare_training_data():\n",
    "    # This is where you'd load your labeled data\n",
    "    # Format: [(word, label, ascii_art), ...]\n",
    "    def read_file_to_string(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    data_pairs = list()\n",
    "    label_list = list()\n",
    "    txt_dir = os.path.join(\"..\", \"Data\", \"Text\")\n",
    "    for txt_file in os.listdir(txt_dir):\n",
    "        if txt_file.endswith(\".txt\"):\n",
    "            #print(txt_file)\n",
    "            ascii_art_txt = read_file_to_string(os.path.join(txt_dir, txt_file))\n",
    "            label = txt_file.split('_')[0]\n",
    "            label_list.append(label)\n",
    "            data_pairs.append(tuple([label, ascii_art_txt]))\n",
    "    \n",
    "    return data_pairs, list(set(label_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "# Load word embeddings\n",
    "import gensim.downloader as api\n",
    "word_model_name = \"glove-twitter-25\"\n",
    "word_model = api.load(word_model_name)\n",
    "embedding_dim = 25\n",
    "\n",
    "# Define dimensions\n",
    "x_dim = 25\n",
    "y_dim = 8\n",
    "output_size = y_dim * x_dim\n",
    "\n",
    "# Define character set\n",
    "ascii_chars = \" .,:;+*#@$%&0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ-_=|/\\\\()[]{}\"\n",
    "num_chars = len(ascii_chars)\n",
    "char_to_index = {char: i for i, char in enumerate(ascii_chars)}\n",
    "index_to_char = {i: char for i, char in enumerate(ascii_chars)}\n",
    "\n",
    "# Initialize model\n",
    "model = ASCIIArtGenerator(embedding_dim, output_size, num_chars)\n",
    "print(\"model initialized\")\n",
    "\n",
    "# Prepare dataset\n",
    "data_pairs, label_list = prepare_training_data()\n",
    "dataset = ASCIIArtDataset(data_pairs, word_model)\n",
    "print(\"dataset prepared\")\n",
    "\n",
    "# Train model\n",
    "trained_model = train_model(model, dataset, label_list, num_epochs=50, learning_rate=0.001)\n",
    "\n",
    "# Test with some words\n",
    "test_words = [\"cat\", \"dog\", \"wolf\", \"eagle\"]\n",
    "for word in test_words:\n",
    "    if word in word_model:\n",
    "        embedding = torch.tensor(word_model[word])\n",
    "        ascii_art = generate_ascii_art(trained_model, embedding, temperature=0.8)\n",
    "        print(f\"ASCII art for '{word}':\")\n",
    "        print(ascii_art)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
