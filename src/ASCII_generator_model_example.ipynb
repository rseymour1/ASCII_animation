{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.3 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Using cached gensim-4.3.3-cp39-cp39-macosx_11_0_arm64.whl (24.0 MB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp39-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch) (4.13.0)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Using cached torch-2.6.0-cp39-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.2.1 sympy-1.13.1 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting Pillow\n",
      "  Using cached pillow-11.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Using cached pillow-11.2.0-cp39-cp39-macosx_11_0_arm64.whl (8.9 MB)\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-11.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl (197 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting open_clip_torch\n",
      "  Using cached open_clip_torch-2.31.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from open_clip_torch) (2.6.0)\n",
      "Collecting torchvision (from open_clip_torch)\n",
      "  Using cached torchvision-0.21.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting regex (from open_clip_torch)\n",
      "  Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting ftfy (from open_clip_torch)\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tqdm (from open_clip_torch)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting huggingface-hub (from open_clip_torch)\n",
      "  Using cached huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from open_clip_torch)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting timm (from open_clip_torch)\n",
      "  Using cached timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Requirement already satisfied: filelock in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub->open_clip_torch)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision->open_clip_torch) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision->open_clip_torch) (11.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (2025.1.31)\n",
      "Using cached open_clip_torch-2.31.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "Using cached torchvision-0.21.0-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, pyyaml, ftfy, huggingface-hub, torchvision, timm, open_clip_torch\n",
      "Successfully installed ftfy-6.3.1 huggingface-hub-0.30.1 open_clip_torch-2.31.0 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 timm-1.0.15 torchvision-0.21.0 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision) (11.2.0)\n",
      "Requirement already satisfied: filelock in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (4.13.0)\n",
      "Requirement already satisfied: networkx in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "%pip install torch\n",
    "%pip install Pillow\n",
    "%pip install requests\n",
    "%pip install open_clip_torch\n",
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gensim.downloader as api # pip install gensim\n",
    "from txt2png import txt_to_png\n",
    "if torch.backends.mps.is_available():\n",
    "    from open_clip_test_mps import clip_loss, device, preprocess\n",
    "elif torch.cuda.is_available():\n",
    "    from open_clip_test_cuda import clip_loss, device, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_name = \"glove-twitter-25\"\n",
    "word_model = api.load(word_model_name)\n",
    "embedding_dim = 25\n",
    "x_dim = 25\n",
    "y_dim = 8\n",
    "output_size = y_dim * x_dim\n",
    "ascii_chars = \" .,:;+*#@$%&0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ-_=|/\\\\()[]{}\"\n",
    "num_chars = len(ascii_chars)\n",
    "char_to_index = {char: i for i, char in enumerate(ascii_chars)}\n",
    "index_to_char = {i: char for i, char in enumerate(ascii_chars)}\n",
    "\n",
    "class ASCIIArtGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_chars):\n",
    "        super(ASCIIArtGenerator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size * num_chars)\n",
    "        self.num_chars = num_chars\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(-1, self.output_size, self.num_chars)\n",
    "\n",
    "def generate_ascii_art(model, embedding, temperature=1.0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(embedding.unsqueeze(0))  # Shape: [1, output_size, num_chars]\n",
    "        \n",
    "        # Apply temperature scaling to logits\n",
    "        scaled_logits = output / temperature\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(scaled_logits, dim=2)\n",
    "        \n",
    "        # Sample from the distribution\n",
    "        # We'll use multinomial sampling which selects based on probabilities\n",
    "        indices = torch.multinomial(probs.view(-1, num_chars), 1).squeeze(-1)\n",
    "        \n",
    "        ascii_grid = \"\"\n",
    "        for i in range(y_dim):\n",
    "            for j in range(x_dim):\n",
    "                ascii_grid += index_to_char[indices[i * x_dim + j].item()]\n",
    "            ascii_grid += \"\\n\"\n",
    "        return ascii_grid\n",
    "\n",
    "model = ASCIIArtGenerator(embedding_dim, output_size, num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 2.1197566986083984\n",
      "O:(T=ogcj)=hW*.c3-qd9lIA]\n",
      "c).0yY8f@hvDJR_y}k=0Mf@.t\n",
      "8s9}IG6H)Vmm9r|5E]xnYx{pN\n",
      "VQmmc]nIpcBQ9GOq\\+5(_3rx|\n",
      "P@v=ws3 rSbTXhSM0bCx:70D8\n",
      " U3TzeaOQ=*y5N9|x)4PzsQel\n",
      "scASw5yShkR]B*;_=U$r8w)-+\n",
      "Jn&4wNr#q KC\\*6NbJZUiC93,\n",
      "\n",
      "Iteration 1, Loss: 2.2376253604888916\n",
      "}uch9ilOhHSiwbLv*7;6rjB%E\n",
      "p5h]S}%Nuf{.O|xLIwrF1@uZ*\n",
      "h3R07BEY2zU(RD4_uojgx2 Oo\n",
      "{tA6pR4Qc9okCT6(+@eL8hKx;\n",
      "$%khdcKoOt:d%Dws\\NpRj$lw;\n",
      "gz9Qt9eoS)(%kFyhmE[]4p\\o_\n",
      "(R HA\\5(Fo{Ued5[n_S;8\\E7b\n",
      "F*a37lKTMOZVZkt%ul7}P3G#A\n",
      "\n",
      "Iteration 2, Loss: 0.708647608757019\n",
      "=PEXnIMRq2p:yc2fdf27cQ2,Q\n",
      "YS9pTQ91+APr_lhWo44$dave(\n",
      "G/WPy$.OdZtzP)aouf2LqG_k4\n",
      "s-{Qf4._${5ro(0I)_rS2)7Nr\n",
      "U4VJPa([JYOP+aEtPHGmdERnf\n",
      "c;vm5%Af#308y#GcWLDUPJYR5\n",
      "&:e)$WcfBHvc[[xyrtmiUK7kL\n",
      "*nlNuvDuS;99Q3PUmCJ70[(k\\\n",
      "\n",
      "Iteration 3, Loss: 1.9367587566375732\n",
      "p2{.G@;EcwS6,8dp)c+Og+H+2\n",
      "Oh43ibl7DUmw;0oGWMAJ:r7.s\n",
      "hkLN:e&HNxB[/#F#gZ8 C5/Q6\n",
      "\\[NfDMwACKPwv|A[|ks)-;:vy\n",
      "gG{TUxaE]I;QwwIdG6/X@hd  \n",
      "+0OAG@SQq*FxVDw.dQZ7e:2Ve\n",
      "{Iiu,jqnV,;T4jk/W/ja}*acz\n",
      "#hr\\[3nkWsjhbnmJFW8|67ce-\n",
      "\n",
      "Iteration 4, Loss: 2.2767608165740967\n",
      "Q8*M4Z9x.\\/aKVQ,.3:=XZ%3[\n",
      "sVBHWX]u8a+XVyV#t}If+zWQB\n",
      ",,-o&0ky,)xTy&Atnl}]oMm@v\n",
      "Bh-Jy*wVj%uP\\S/4-odgNZgJs\n",
      "c|}CZ-|w InHhBKQNW7Rq8dS#\n",
      "WIylm#ToREaHsTz_IcioM66gi\n",
      "m(A\\90g:vaM7Ir;7onT{TeR-m\n",
      "uN|4xeW\\BQB[e*kJI&A+%9{rM\n",
      "\n",
      "Iteration 5, Loss: 1.8594872951507568\n",
      "S8R7%F}86HOovTA#h5y%9DQvh\n",
      ":iPsu3.L6fr%nSp/11GzdQ:D@\n",
      "@dNQquOUFR-dU.ehHHqgaZRyY\n",
      "RC7RV)wFwn8QA-T+Htz,ljS3u\n",
      "m_R8BK(:#o.+]_6Tdh@8hthpE\n",
      "]vzhwVQwcHzn&O5iVuDtaEbsT\n",
      "WD8OrMcXkt ]lvaH*{OteRP&U\n",
      "Hi0Z(yH;w5zxz86vSV()nvlF/\n",
      "\n",
      "Iteration 6, Loss: 0.5768875479698181\n",
      "uIa+.}c&KPjCX10IH#3/,a{78\n",
      "B2iBGjadqYYrdZ2o8:-23/WeS\n",
      "v7]H{hM/#Zv(4_NiymAQ5Lya:\n",
      "uczNY9XBgZI,r4IE)T+aO@,xc\n",
      "X6g;5|edT:Ps.+6L5BaQ=cPAa\n",
      ";[joK=yF0\\895YF3}}mXuv[Ig\n",
      "aYF:S)C=9TPeaL1VDn,vnQRtc\n",
      ",e4[n\\gnn[wfedgf5XED.lG6*\n",
      "\n",
      "Iteration 7, Loss: 3.279086112976074\n",
      "h#K$2dLsk @EY:O;lkiP3O9iS\n",
      "_Ix1/=0ucmW(HhNy/X&*ltq+d\n",
      "{Vmq-=ecoO/E;D/Ua*Q7Y::Pj\n",
      "IIzq94/tz7*;4[Yb#\\Udoz2#S\n",
      "(FDAz8$F/yns|[Lh_Gf}8Nv(Q\n",
      "qy*8(uT_U;30}0GS;LhwM*];2\n",
      "}2zKJ*q1y6W5yAJ\\$*#2=HRuc\n",
      "f}Qz[5-@5L{ u\\zlAn\\0d9sc/\n",
      "\n",
      "Iteration 8, Loss: 1.106422781944275\n",
      "DIv[tHS-qVK7]jmR8IpRd[oJ;\n",
      "HWIv6nY$lW,wb/S=D=IQZI55B\n",
      "KF7XM5xBu_*; 9}.HFv7\\beB.\n",
      "Bu.ofPO9-DmwU LxTYe32XMSm\n",
      "yi}MH.X{K_ED\\ZS]Ya@B3Vnl\\\n",
      "n*Tl&niqOLinVPMdhcIyuWstT\n",
      "QOtM2\\xal_EUud89.|T19AIa$\n",
      "/-HV RM,jSE}bL2\\5U2x52(TR\n",
      "\n",
      "Iteration 9, Loss: 0.7435727715492249\n",
      "fY.%F|uL+LMIx:/f($u}2gY;W\n",
      "bZ2g]:m|wz-$bw]x{LH)oJsUv\n",
      "_1_j%Zpg&SRxn.e,9+@cSby8@\n",
      "om&8e3x=/vE6gO*vFf[*+oT;5\n",
      "R+VN\\(=rt fpO1|%bJ4Sa.KB+\n",
      "3fP0A*0eAwGv\\b5]ODl&(}k)l\n",
      "O-_Zhm.e.RD/druGiUGVW%us2\n",
      "Vt%q=qSp[B5KhF_V/@*%iBmD+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding = torch.tensor(word_model[\"cat\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr = .001)\n",
    "for i in range(10):\n",
    "    ascii_art = generate_ascii_art(model, embedding, temperature=.5)\n",
    "    ascii_png = txt_to_png(ascii_art, output_png=\"temp.png\", save=True)\n",
    "    image_tensor = preprocess(ascii_png).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "    optimizer.zero_grad()\n",
    "    candidate_labels = [\"bird\", \"dog\", \"cat\", \"castle\"]\n",
    "    true_label = 2\n",
    "    loss = clip_loss(image_tensor, candidate_labels, true_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Iteration {i}, Loss: {loss.item()}\")\n",
    "    print(ascii_art)\n",
    "    #print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
