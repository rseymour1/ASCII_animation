{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.3 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Using cached gensim-4.3.3-cp39-cp39-macosx_11_0_arm64.whl (24.0 MB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp39-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch) (4.13.0)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Using cached torch-2.6.0-cp39-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.2.1 sympy-1.13.1 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting Pillow\n",
      "  Using cached pillow-11.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Using cached pillow-11.2.0-cp39-cp39-macosx_11_0_arm64.whl (8.9 MB)\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-11.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl (197 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting open_clip_torch\n",
      "  Using cached open_clip_torch-2.31.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from open_clip_torch) (2.6.0)\n",
      "Collecting torchvision (from open_clip_torch)\n",
      "  Using cached torchvision-0.21.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting regex (from open_clip_torch)\n",
      "  Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting ftfy (from open_clip_torch)\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tqdm (from open_clip_torch)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting huggingface-hub (from open_clip_torch)\n",
      "  Using cached huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from open_clip_torch)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting timm (from open_clip_torch)\n",
      "  Using cached timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Requirement already satisfied: filelock in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub->open_clip_torch)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision->open_clip_torch) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision->open_clip_torch) (11.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (2025.1.31)\n",
      "Using cached open_clip_torch-2.31.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "Using cached torchvision-0.21.0-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, pyyaml, ftfy, huggingface-hub, torchvision, timm, open_clip_torch\n",
      "Successfully installed ftfy-6.3.1 huggingface-hub-0.30.1 open_clip_torch-2.31.0 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 timm-1.0.15 torchvision-0.21.0 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torchvision) (11.2.0)\n",
      "Requirement already satisfied: filelock in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (4.13.0)\n",
      "Requirement already satisfied: networkx in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dalfr76/Documents/CS_673/ASCII_animation/.venv/lib/python3.9/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "%pip install torch\n",
    "%pip install Pillow\n",
    "%pip install requests\n",
    "%pip install open_clip_torch\n",
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gensim.downloader as api # pip install gensim\n",
    "from txt2png import txt_to_png\n",
    "from open_clip_test_mps import clip_loss, device, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_name = \"glove-twitter-25\"\n",
    "word_model = api.load(word_model_name)\n",
    "embedding_dim = 25\n",
    "x_dim = 25\n",
    "y_dim = 8\n",
    "output_size = y_dim * x_dim\n",
    "ascii_chars = \" .,:;+*#@$%&0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ-_=|/\\\\()[]{}\"\n",
    "num_chars = len(ascii_chars)\n",
    "char_to_index = {char: i for i, char in enumerate(ascii_chars)}\n",
    "index_to_char = {i: char for i, char in enumerate(ascii_chars)}\n",
    "\n",
    "class ASCIIArtGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_chars):\n",
    "        super(ASCIIArtGenerator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size * num_chars)\n",
    "        self.num_chars = num_chars\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(-1, self.output_size, self.num_chars)\n",
    "\n",
    "def generate_ascii_art(model, embedding, temperature=1.0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(embedding.unsqueeze(0))  # Shape: [1, output_size, num_chars]\n",
    "        \n",
    "        # Apply temperature scaling to logits\n",
    "        scaled_logits = output / temperature\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(scaled_logits, dim=2)\n",
    "        \n",
    "        # Sample from the distribution\n",
    "        # We'll use multinomial sampling which selects based on probabilities\n",
    "        indices = torch.multinomial(probs.view(-1, num_chars), 1).squeeze(-1)\n",
    "        \n",
    "        ascii_grid = \"\"\n",
    "        for i in range(y_dim):\n",
    "            for j in range(x_dim):\n",
    "                ascii_grid += index_to_char[indices[i * x_dim + j].item()]\n",
    "            ascii_grid += \"\\n\"\n",
    "        return ascii_grid\n",
    "\n",
    "model = ASCIIArtGenerator(embedding_dim, output_size, num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.5660963654518127\n",
      "O|V&/dc[*4t(9,zkZkwp7H=Q_\n",
      "Bbh1wM(.;1):I/D,E(|Sf]m@|\n",
      "WmGwVG4RQD_y;bM]d&JkY;-j5\n",
      "5P -bmC6&;g IHhY:2JxHETp$\n",
      "\\0EzJ.m8]p;dc-[pogRBb-B=$\n",
      "9FuW=YD2lAnjdJ$+uFl(ehfFx\n",
      "%&)kK-=#{{Ppncy$,(Qkyrws:\n",
      "3W[m*fkzU[&pmf5G#\\wm}@\\ :\n",
      "\n",
      "\n",
      "Iteration 1, Loss: 1.252697467803955\n",
      "$C.@2:8&g${N/R$nl+BJpbOg{\n",
      "\\s-Oy9EaclxKBaL8UH{+2RFd#\n",
      "My\\AGt2-mwtE)l3/}_hur2JhH\n",
      "#Y;,l|8X&-k\\.C=y;xu{LeW=n\n",
      "]djr%sSYsNx,a#zUcj:xnSfqI\n",
      "uKN=YAWxh[SXBx&}WSFCz]DaS\n",
      "qyjGQtVgoVBhY0p2lx@70Y%OH\n",
      "]XAH3PfO p-}%]s;2\\h|2zq{,\n",
      "\n",
      "\n",
      "Iteration 2, Loss: 0.7567050457000732\n",
      "SEK +Zw|Y;[QwOV]a,H0KNsU[\n",
      "Z/vb|A7.5dx@xqjUvk %Y(Ale\n",
      "e}o bSF97cdWBKgz+BxJy\\__$\n",
      "-)fzC6$H+i%73fVYbi3iuzkB[\n",
      "}(ef7Rc,/xnm9@sRqaH#I:vO(\n",
      "frWgP)&CnEBOz*7KukxD :0%:\n",
      "u+,bIo,Y2kPIuqfDs+B}aI y7\n",
      "$*cS)ru2e=PV[M]_E8ut_wzNP\n",
      "\n",
      "\n",
      "Iteration 3, Loss: 0.4970836937427521\n",
      "4SJTl)hkcPDUfeH8EoFy{} #2\n",
      "EOH-SISp#lNEPyG5XO$HqvN1P\n",
      "t0own5r0xRU;:1.F|,XsCQMC4\n",
      ",Pg6Tf98k)eWbY\\6)wgR}EVA:\n",
      "0h/(Nc1VCr*HyWP6kUYGz7+Lh\n",
      ")Aa=I0uLgm[eGHyU:*yMDNcS6\n",
      "hsw9ulVU1TjmM)}GQqh6D(xcn\n",
      "FNY1fi3JGCJ:LCDVP$9-9WX-G\n",
      "\n",
      "\n",
      "Iteration 4, Loss: 0.6366037130355835\n",
      "\\tvbS()1bUBj5{i(7bUFH|E)i\n",
      "7L Q0d/asApSKt]mE=vm&g:nY\n",
      "$bT6tCzXcKBJ/Zw$N{SKbKF5-\n",
      "30v9D0yofSfW#-Aq*=NUfi0J#\n",
      "Yr6zAhjRsz&Dy@{\\KcEOE,bMx\n",
      "kY8%jqwe{,dS4d#J}G$jBCTT;\n",
      "IX6H$Gt:]N2{Ihp+Jl1F=:K#z\n",
      "Uj3;kg +OI(oXC|A=lUpQ7igR\n",
      "\n",
      "\n",
      "Iteration 5, Loss: 0.5751412510871887\n",
      "jN4LdphQ0X1%KOa;j]&B}kccJ\n",
      "EzG9gs)aeU|EJnPi#jsfYvJ+R\n",
      "m/x9 YeiMAb*b2#2q5:&_q7xG\n",
      ":D&9DIwMmE1&ED;Bc__T}QfFb\n",
      "UF[fgIWfkbw55gh=h,N7S3(:$\n",
      ",-5@+Nx&LLqf/9YBNJOz4x)rs\n",
      "B{ho]7w*,Q6AwcX@,Y@+l%XDM\n",
      "*d2\\aL4M4oX-KNmv *w5G-O5$\n",
      "\n",
      "\n",
      "Iteration 6, Loss: 0.872356116771698\n",
      "X2w.Om=sp]\\XK$r)1.DKxBt=B\n",
      ":)Qcf)Ioqsww9o6S2Vv=@0Ana\n",
      "gZ3R9&b&pNjXnCxWsTEVF#$RJ\n",
      "s A|;(Zq}Ht6W$&(}SiQ0p8Tb\n",
      "LHQ,Z(S8x};bSw0yj6z8{yY|2\n",
      "&+hLDdb=tx|#oe@ A9KCgyMYY\n",
      "G\\.lJFO+*,l7av@9jSsh5 2#O\n",
      "@OKG-yE7)X(EKHPE 5dSTj5US\n",
      "\n",
      "\n",
      "Iteration 7, Loss: 0.5603382587432861\n",
      "y5hGd0a;Bn3%5mJEbNG%ZUfkL\n",
      "\\[QJnsPM2z*ndqNZAu3-T4Z8L\n",
      "Le]CE*W$GB}xCv]wsR1a|neN;\n",
      "vWX2q*W//hM{Vw)GmF31@B5Gc\n",
      "XZFbk&q=kK.2.[c:(.\\nE1rj[\n",
      "-=Q:tc1Fn8GnKb-92/nD,PMrV\n",
      "XJ1:|1T/UU4q54yYL*|Q0iWw*\n",
      "5|s+;S@2]N6&u\\4w*_LP0NuTL\n",
      "\n",
      "\n",
      "Iteration 8, Loss: 0.7583599090576172\n",
      "P@FMUPNk-r$\\{_j2\\ZkF7M;FU\n",
      "zbA1ow(CgYfi|_v2g75#QbOn=\n",
      "#fMKkUOhmVvpc1\\_QIT|]qiYi\n",
      "jX=[ZZG:2aXd1=(0sCp=8fRM0\n",
      "AoQlgscOTi=Ggg-pyw|4@rx\\K\n",
      "n(m&#9.u1gJvSQaTHDGBfZU)N\n",
      "R%q|(*0FC]N/E-&@G*K7NA,Nr\n",
      "BuLb/}Uosr5 q|:|@*0)0cg;i\n",
      "\n",
      "\n",
      "Iteration 9, Loss: 0.3091471493244171\n",
      "52@ta5}gif+$a| 2H}(X%KCqB\n",
      "OdDwOPbg)+SMI3DbMJOeXW#L)\n",
      "ok+G.AXI|x\\%4Y-1#ZhD%RN|t\n",
      "SRjyPEu8Lcex@zbg/\\xUcspB6\n",
      "#a\\bBTmNPuZ])gn%H,Gsbjk3w\n",
      "W)Y4h6ELB$Rmk_zUV3iA2(YQP\n",
      "Nvttu1+L{U@+jEvF{](Y*T4@4\n",
      ":s0D%|;mRf#83S]w#z5X|K,p2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding = torch.tensor(word_model[\"cat\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr = .01)\n",
    "for i in range(10):\n",
    "    ascii_art = generate_ascii_art(model, embedding)\n",
    "    ascii_png = txt_to_png(ascii_art, output_png=\"temp.png\", save=True)\n",
    "    image_tensor = preprocess(ascii_png).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "    optimizer.zero_grad()\n",
    "    candidate_labels = [\"bird\", \"dog\", \"cat\", \"castle\"]\n",
    "    true_label = 2\n",
    "    loss = clip_loss(image_tensor, candidate_labels, true_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Iteration {i}, Loss: {loss.item()}\")\n",
    "    print(ascii_art)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
